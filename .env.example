# Gemini API Configuration
GEMINI_API_KEY=your_gemini_api_key_here

# Database Configuration (optional - defaults in session.py)
# DATABASE_URL=postgresql://postgres:1234567890@localhost:5432/postgres

# Database Connection Pooling (Phase 1: Scaling improvements)
# DB_POOL_SIZE=20                    # Base connection pool size
# DB_MAX_OVERFLOW=40                 # Max connections beyond pool_size
# DB_POOL_RECYCLE=3600               # Recycle connections after N seconds
# DB_POOL_TIMEOUT=30                 # Timeout for getting connection (seconds)
# DB_ECHO=false                      # Enable SQL query logging (for debugging)

# Read Replica (optional - for read-heavy workloads)
# DATABASE_URL_READ=postgresql://postgres:1234567890@read-replica-host:5432/postgres
# DB_READ_POOL_SIZE=30               # Read replica pool size
# DB_READ_MAX_OVERFLOW=60            # Read replica max overflow

# Redis Configuration (Phase 1: Caching)
# REDIS_HOST=localhost               # Redis host (default: localhost)
# REDIS_PORT=6379                    # Redis port (default: 6379)
# REDIS_DB=0                         # Redis database number (default: 0)
# Note: Redis is optional - the app will work without it, but caching will be disabled

# Embedding Provider Configuration
# EMBEDDING_PROVIDER=gemini           # Options: gemini, sbert, openai, mock
# USE_MOCK_EMBEDDING=false           # Force mock embeddings (for offline/dev)
# SBERT_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
